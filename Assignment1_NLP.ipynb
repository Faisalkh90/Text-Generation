{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "5h3Co58u5myG"
      },
      "source": [
        "### Name: Faisal Mansour Alkhalifah\n",
        "\n",
        "### ID: 440025849"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "##### I assumed the following:\n",
        "- Tokenizes a corpus of text.\n",
        "- Generates n-gram models from 2-6.\n",
        "- Produce random phrases.\n",
        "- Find and save the 10 high frequent (trigram) in the corpus in a text file \n",
        "- The user enters desired sentence\n",
        "- The user enters the seed word\n",
        "- Print the sentence"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**1- Downloads the data required for tokenization. It also imports a number of modules for text processing and generation.**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HzSIDCf59SSL",
        "outputId": "f8b7d648-2e37-497a-d7da-4a365d5ceb29"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: nltk in c:\\users\\user\\appdata\\roaming\\python\\python39\\site-packages (3.8.1)\n",
            "Requirement already satisfied: click in c:\\users\\user\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from nltk) (7.1.2)\n",
            "Requirement already satisfied: joblib in c:\\users\\user\\appdata\\roaming\\python\\python39\\site-packages (from nltk) (1.2.0)\n",
            "Requirement already satisfied: regex>=2021.8.3 in c:\\users\\user\\appdata\\roaming\\python\\python39\\site-packages (from nltk) (2023.3.23)\n",
            "Requirement already satisfied: tqdm in c:\\users\\user\\appdata\\roaming\\python\\python39\\site-packages (from nltk) (4.65.0)\n",
            "Requirement already satisfied: colorama in c:\\users\\user\\appdata\\roaming\\python\\python39\\site-packages (from tqdm->nltk) (0.4.6)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "[notice] A new release of pip available: 22.3.1 -> 23.0.1\n",
            "[notice] To update, run: python.exe -m pip install --upgrade pip\n",
            "[nltk_data] Downloading package punkt to\n",
            "[nltk_data]     C:\\Users\\User\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        }
      ],
      "source": [
        "!pip install --user -U nltk\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "import random\n",
        "from nltk.tokenize import word_tokenize\n",
        "import collections"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**2- Load the corpus from KSUCCA Corpus Files**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "f = open(\"aa1.txt\", \"r\", encoding=\"utf-8\")\n",
        "corpus = f.read()\n",
        "f.close()"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**3- Tokenize the corpus and generate N-gram models for n = 2 to 6**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [],
      "source": [
        "tokens = word_tokenize(corpus)\n",
        "\n",
        "ngram_models = {}\n",
        "for n in range(2, 7):\n",
        "    ngrams = zip(*[tokens[i:] for i in range(n)])\n",
        "    ngram_models[n] = list(ngrams)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**4- Get the 10 most frequent trigrams and save it into  frequent.txt**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [],
      "source": [
        "trigrams = ngram_models[3]\n",
        "freq_dist = collections.Counter(trigrams)\n",
        "\n",
        "common = freq_dist.most_common(10)\n",
        "\n",
        "f = open(\"frequent.txt\", \"w\", encoding=\"utf-8\")\n",
        "for trigram, frequency in common:\n",
        "    f.write(f\"Trigram: {trigram}: Frequency: {frequency}\\n\")\n",
        "f.close()"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**5- Ask the user enters desired sentence and the seed word then generate the sentence**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ejH6estp5LNg",
        "outputId": "34cf9d7f-1a32-4741-b68f-a55572d3b1de"
      },
      "outputs": [
        {
          "ename": "TypeError",
          "evalue": "can only concatenate str (not \"list\") to str",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[11], line 21\u001b[0m\n\u001b[0;32m     15\u001b[0m             \u001b[39mbreak\u001b[39;00m\n\u001b[0;32m     16\u001b[0m     \u001b[39mreturn\u001b[39;00m generated_sentence\n\u001b[1;32m---> 21\u001b[0m generated \u001b[39m=\u001b[39m generate_sentence()\n\u001b[0;32m     23\u001b[0m \u001b[39mprint\u001b[39m(generated)\n",
            "Cell \u001b[1;32mIn[11], line 13\u001b[0m, in \u001b[0;36mgenerate_sentence\u001b[1;34m()\u001b[0m\n\u001b[0;32m     10\u001b[0m     possible_followers \u001b[39m=\u001b[39m [follower \u001b[39mfor\u001b[39;00m (a, b, follower) \u001b[39min\u001b[39;00m trigrams \u001b[39mif\u001b[39;00m a \u001b[39m==\u001b[39m generated_sentence\u001b[39m.\u001b[39msplit()[\u001b[39m-\u001b[39m\u001b[39m2\u001b[39m] \u001b[39mand\u001b[39;00m b \u001b[39m==\u001b[39m generated_sentence\u001b[39m.\u001b[39msplit()[\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m]]\n\u001b[0;32m     12\u001b[0m \u001b[39mif\u001b[39;00m possible_followers:\n\u001b[1;32m---> 13\u001b[0m     generated_sentence \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m\"\u001b[39;49m\u001b[39m \u001b[39;49m\u001b[39m\"\u001b[39;49m \u001b[39m+\u001b[39;49m possible_followers\n\u001b[0;32m     14\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m     15\u001b[0m     \u001b[39mbreak\u001b[39;00m\n",
            "\u001b[1;31mTypeError\u001b[0m: can only concatenate str (not \"list\") to str"
          ]
        }
      ],
      "source": [
        "# generate sentence function \n",
        "def generate_sentence():\n",
        "    num_words = int(input(\"Enter the number of words in the desired sentence: \"))\n",
        "    start_word = input(\"Enter a start word: \")\n",
        "    generated_sentence = start_word\n",
        "    while len(generated_sentence.split()) < num_words:\n",
        "        if len(generated_sentence.split()) < 2:\n",
        "            possible_followers = [follower for (a, follower) in ngram_models[2] if a == generated_sentence.split()[-1]]\n",
        "        else:\n",
        "            possible_followers = [follower for (a, b, follower) in trigrams if a == generated_sentence.split()[-2] and b == generated_sentence.split()[-1]]\n",
        "            \n",
        "        if possible_followers:\n",
        "            generated_sentence += \" \" + random.choice(possible_followers)\n",
        "        else:\n",
        "            break\n",
        "    return generated_sentence\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# generated = generate_sentence()\n",
        "        \n",
        "# print(generated)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**6- Test and Result**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [],
      "source": [
        "# for i in range(10):\n",
        "#     # generated = generate_sentence()\n",
        "#     print(generate_sentence())    "
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
